{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba69900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc525523",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\"..\", \"data\", \"Loan_default.csv\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeafa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.dtypes.value_counts())\n",
    "display(df.isna().mean().sort_values(ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8513378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert \"Default\" in df.columns, \"No encuentro la columna 'Default' en el dataset.\"\n",
    "\n",
    "y = df[\"Default\"]\n",
    "X = df.drop(columns=[\"Default\"])\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "display(y.value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59586f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y.value_counts(dropna=False)\n",
    "props = y.value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "print(\"Counts:\")\n",
    "display(counts)\n",
    "\n",
    "print(\"\\nProportions (%):\")\n",
    "display(props)\n",
    "\n",
    "props.sort_index().plot(kind=\"bar\")\n",
    "plt.title(\"Default distribution (0/1)\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df\n",
    "    .groupby(\"Default\")[\"Income\"]\n",
    "    .describe()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5985bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credit Score\n",
    "\n",
    "display(\n",
    "    df\n",
    "    .groupby(\"Default\")[\"CreditScore\"]\n",
    "    .describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ffa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTIRatio\n",
    "display(\n",
    "    df\n",
    "    .groupby(\"Default\")[\"DTIRatio\"]\n",
    "    .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60670fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EmploymentType\n",
    "default_rate_emp = (\n",
    "    df\n",
    "    .groupby(\"EmploymentType\")[\"Default\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "display(default_rate_emp)\n",
    "\n",
    "default_rate_emp.plot(kind=\"bar\")\n",
    "plt.title(\"Default rate by EmploymentType\")\n",
    "plt.ylabel(\"Default rate\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a17d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Default\"]\n",
    "X = df.drop(columns=[\"Default\"])\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"\\nCategorical columns:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape :\", X_test.shape)\n",
    "\n",
    "print(\"\\nDefault rate train:\", y_train.mean())\n",
    "print(\"Default rate test :\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d77e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "X_train_num = sparse.csr_matrix(X_train[num_cols].to_numpy(dtype=np.float32))\n",
    "X_test_num  = sparse.csr_matrix(X_test[num_cols].to_numpy(dtype=np.float32))\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\", sparse_output=True)  # use sparse=True if needed\n",
    "\n",
    "X_train_cat = ohe.fit_transform(X_train[cat_cols])\n",
    "X_test_cat  = ohe.transform(X_test[cat_cols])\n",
    "\n",
    "X_train_final = sparse.hstack([X_train_num, X_train_cat], format=\"csr\")\n",
    "X_test_final  = sparse.hstack([X_test_num, X_test_cat], format=\"csr\")\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_test_scaled  = scaler.transform(X_test_final)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83009e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=None\n",
    ")\n",
    "\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "proba_lr = logreg.predict_proba(X_test_scaled)[:, 1]\n",
    "auc_lr = roc_auc_score(y_test, proba_lr)\n",
    "\n",
    "auc_lr\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred_lr = (proba_lr >= 0.5).astype(int)\n",
    "\n",
    "confusion_matrix(y_test, pred_lr)\n",
    "\n",
    "print(classification_report(y_test, pred_lr, digits=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f77a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_lr = roc_auc_score(y_test, proba_lr)\n",
    "roc_auc_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, proba_lr)\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"LogReg (AUC = {roc_auc_lr:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Logistic Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "\n",
    "X_train_svd = svd.fit_transform(X_train_final)\n",
    "X_test_svd  = svd.transform(X_test_final)\n",
    "\n",
    "X_train_svd.shape, X_test_svd.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f748842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    random_state=42,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "hgb.fit(X_train_svd, y_train)\n",
    "\n",
    "proba_hgb = hgb.predict_proba(X_test_svd)[:, 1]\n",
    "roc_auc_hgb = roc_auc_score(y_test, proba_hgb)\n",
    "\n",
    "roc_auc_hgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae05af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "pred_hgb = (proba_hgb >= 0.5).astype(int)\n",
    "\n",
    "confusion_matrix(y_test, pred_hgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4dcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_hgb, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, proba_lr)\n",
    "fpr_hgb, tpr_hgb, _ = roc_curve(y_test, proba_hgb)\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"LogReg (AUC={roc_auc_lr:.3f})\")\n",
    "plt.plot(fpr_hgb, tpr_hgb, label=f\"HistGB+SVD (AUC={roc_auc_hgb:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a693ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def eval_threshold(y_true, proba, thr):\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "    return {\n",
    "        \"thr\": thr,\n",
    "        \"tp\": tp, \"fn\": fn, \"fp\": fp, \"tn\": tn,\n",
    "        \"recall_1\": tp/(tp+fn) if (tp+fn) else 0,\n",
    "        \"precision_1\": tp/(tp+fp) if (tp+fp) else 0\n",
    "    }\n",
    "\n",
    "pd.DataFrame([eval_threshold(y_test.values, proba_hgb, t)\n",
    "              for t in [0.10, 0.15, 0.20, 0.25, 0.30, 0.40, 0.50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d84241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, numpy as np\n",
    "\n",
    "t0 = time.time()\n",
    "_ = X_train_final[:2000].astype(np.float32).toarray()\n",
    "print(\"dense slice seconds:\", round(time.time()-t0, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c0c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train_ebm = X_train_red.astype(np.float32).toarray()\n",
    "X_test_ebm  = X_test_red.astype(np.float32).toarray()\n",
    "\n",
    "print(\"Reduced shapes:\", X_train_ebm.shape, X_test_ebm.shape, flush=True)\n",
    "\n",
    "ebm = ExplainableBoostingClassifier(\n",
    "    random_state=42,\n",
    "    interactions=0,\n",
    "    max_bins=64,\n",
    "    learning_rate=0.05,\n",
    "    max_rounds=500,\n",
    "    outer_bags=1,\n",
    "    inner_bags=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "ebm.fit(X_train_ebm, y_train)\n",
    "print(\"fit seconds:\", round(time.time()-t0, 2), flush=True)\n",
    "\n",
    "proba_ebm = ebm.predict_proba(X_test_ebm)[:, 1]\n",
    "roc_auc_ebm = roc_auc_score(y_test, proba_ebm)\n",
    "print(\"ROC AUC:\", round(roc_auc_ebm, 4), flush=True)\n",
    "\n",
    "fpr_ebm, tpr_ebm, _ = roc_curve(y_test, proba_ebm)\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, label=f\"LogReg (AUC={roc_auc_lr:.3f})\")\n",
    "plt.plot(fpr_hgb, tpr_hgb, label=f\"HistGB+SVD (AUC={roc_auc_hgb:.3f})\")\n",
    "plt.plot(fpr_ebm, tpr_ebm, label=f\"EBM (AUC={roc_auc_ebm:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07abdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# feature names\n",
    "feature_names_red = [feature_names[k] for k in keep_cols]\n",
    "n_features = len(feature_names_red)\n",
    "\n",
    "# select a client with mixed contributions\n",
    "order = np.argsort(-proba_ebm)\n",
    "\n",
    "chosen_i = None\n",
    "chosen_top = None\n",
    "chosen_pd = None\n",
    "\n",
    "for i in order[:2000]:\n",
    "    exp = ebm.explain_local(X_test_ebm[i:i+1], y_test.iloc[i:i+1])\n",
    "    data = exp.data(0)\n",
    "\n",
    "    contrib = np.array(data[\"scores\"], dtype=float)\n",
    "\n",
    "    if len(contrib) == n_features + 1:\n",
    "        contrib = contrib[:-1]\n",
    "\n",
    "    if len(contrib) != n_features:\n",
    "        continue\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"feature\": feature_names_red,\n",
    "        \"contribution\": contrib\n",
    "    })\n",
    "\n",
    "    df[\"abs_contribution\"] = df[\"contribution\"].abs()\n",
    "    df = df.sort_values(\"abs_contribution\", ascending=False)\n",
    "\n",
    "    top = df.head(10)\n",
    "\n",
    "    if (top[\"contribution\"] > 0).any() and (top[\"contribution\"] < 0).any():\n",
    "        chosen_i = int(i)\n",
    "        chosen_pd = float(proba_ebm[i])\n",
    "        chosen_top = top.copy()\n",
    "        break\n",
    "\n",
    "# fallback\n",
    "if chosen_i is None:\n",
    "    chosen_i = int(order[0])\n",
    "    chosen_pd = float(proba_ebm[chosen_i])\n",
    "\n",
    "    exp = ebm.explain_local(X_test_ebm[chosen_i:chosen_i+1], y_test.iloc[chosen_i:chosen_i+1])\n",
    "    data = exp.data(0)\n",
    "    contrib = np.array(data[\"scores\"], dtype=float)\n",
    "\n",
    "    if len(contrib) == n_features + 1:\n",
    "        contrib = contrib[:-1]\n",
    "\n",
    "    chosen_top = pd.DataFrame({\n",
    "        \"feature\": feature_names_red,\n",
    "        \"contribution\": contrib\n",
    "    })\n",
    "\n",
    "    chosen_top[\"abs_contribution\"] = chosen_top[\"contribution\"].abs()\n",
    "    chosen_top = chosen_top.sort_values(\"abs_contribution\", ascending=False).head(10)\n",
    "\n",
    "# relative impact\n",
    "total_abs = chosen_top[\"abs_contribution\"].sum()\n",
    "chosen_top[\"relative_impact_pct\"] = 100 * chosen_top[\"abs_contribution\"] / total_abs\n",
    "\n",
    "# clean table\n",
    "chosen_top = chosen_top[[\n",
    "    \"feature\",\n",
    "    \"contribution\",\n",
    "    \"relative_impact_pct\"\n",
    "]]\n",
    "\n",
    "print(f\"Example client (test index): {chosen_i}\")\n",
    "print(f\"Estimated PD: {chosen_pd:.2%}\")\n",
    "\n",
    "display(chosen_top)\n",
    "\n",
    "# plot\n",
    "plot_df = chosen_top.sort_values(\"contribution\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": \"#F3F4F6\",\n",
    "    \"axes.facecolor\": \"white\",\n",
    "    \"axes.edgecolor\": \"#E5E7EB\",\n",
    "    \"font.family\": \"sans-serif\"\n",
    "})\n",
    "\n",
    "colors = [\"#DC2626\" if v > 0 else \"#16A34A\" for v in plot_df[\"contribution\"]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "ax.barh(\n",
    "    plot_df[\"feature\"],\n",
    "    plot_df[\"contribution\"],\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "ax.axvline(0, color=\"#9CA3AF\", linewidth=1)\n",
    "ax.grid(axis=\"x\", linestyle=\"--\", alpha=0.25)\n",
    "\n",
    "for spine in [\"top\", \"right\", \"left\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Credit Risk Drivers â€“ Example Client\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    x=0.02,\n",
    "    ha=\"left\"\n",
    ")\n",
    "\n",
    "ax.set_title(\n",
    "    f\"Estimated Probability of Default: {chosen_pd:.2%}\",\n",
    "    fontsize=11,\n",
    "    loc=\"left\",\n",
    "    color=\"#4B5563\",\n",
    "    pad=12\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Contribution to risk (log-odds)\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "plt.savefig(\"ebm_waterfall.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
